#!/usr/bin/env python3
"""
Test rapide des deux services de scraping
"""

import os
import sys

print("ğŸ§ª TEST DES SERVICES DE SCRAPING")
print("="*60)

# VÃ©rifier les clÃ©s API
print("\nğŸ“Š Configuration actuelle :")
print(f"- SCRAPING_SERVICE : {os.getenv('SCRAPING_SERVICE', 'scrapingbee (par dÃ©faut)')}")
print(f"- SCRAPINGBEE_API_KEY : {'âœ… DÃ©finie' if os.getenv('SCRAPINGBEE_API_KEY') else 'âŒ Non dÃ©finie'}")
print(f"- SCRAPERAPI_KEY : {'âœ… DÃ©finie' if os.getenv('SCRAPERAPI_KEY') else 'âœ… ClÃ© par dÃ©faut disponible'}")

print("\nğŸ”§ Corrections appliquÃ©es :")
print("1. âœ… Status 'skipped_existing' au lieu de 'skipped_existing_url'")
print("2. âœ… Ne pas marquer les URLs dÃ©jÃ  existantes dans processed_urls")
print("3. âœ… Support multi-service maintenu")

print("\nğŸš€ Pour tester :")
print("-"*40)

print("\n# Test rapide avec ScrapingBee (si la clÃ© est valide)")
print("python main_crawler_tokyo_cheapo.py --service scrapingbee --limit 2")

print("\n# Test avec ScraperAPI (271 crÃ©dits disponibles)")
print("python main_crawler_tokyo_cheapo.py --service scraperapi --limit 5")

print("\n# Test complet des attractions avec ScraperAPI")
print("python main_crawler_tokyo_cheapo.py --service scraperapi --target attractions")

print("\nğŸ’¡ Notes :")
print("- Les 466 URLs dÃ©jÃ  scrapÃ©es seront automatiquement skippÃ©es")
print("- Aucun crÃ©dit API ne sera utilisÃ© pour les URLs existantes")
print("- ScraperAPI offre 100k requÃªtes/mois vs 50k pour ScrapingBee")
print("="*60)